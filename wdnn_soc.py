# -*- coding: utf-8 -*-
"""wide and deep soc paper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_M1y5mcf6xZSpG6B8s0o3QWlNlguO3fN
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Dense, concatenate, Flatten
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error
from tensorflow import feature_column as fc
from sklearn.metrics import accuracy_score
from keras import optimizers
from keras import losses
from keras.callbacks import Callback

# Load the data into a Pandas dataframe
data = pd.read_csv("battery_dataset.csv")

# Check for missing values
print(data.isnull().sum())

# Replace missing values with the mean value of each column
data.fillna(data.mean(), inplace=True)

# Split the data into features (x) and target (y)
x = data.iloc[:, :-1]
y = data.iloc[:, -1]

wdnn_rmse_values = []
wdnn_mae_values = []
wdnn_max_abs_error_values = []

for i in range(3):

  # Split the data into training and testing sets
  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)

  # Define the input layer with a specified input shape
  inputs = Input(shape=(5,))
  # Define the wide columns
  wide_layer = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=1))(inputs)
  wide_layer = tf.keras.layers.Flatten()(wide_layer)

  # Define the deep layers
  deep_layer = Dense(1024, activation='relu')(inputs)
  deep_layer = Dense(512, activation='relu')(deep_layer)
  deep_layer = Dense(256, activation='relu')(deep_layer)

  # Concatenate the wide and deep layers
  merged = concatenate([wide_layer, deep_layer])

  # Add a Flatten layer to ensure that the output has a defined shape
  merged = Flatten()(merged)
  # Define the output layer
  output_layer = Dense(1, activation='sigmoid')(merged)

  # Create the model
  model = keras.Model(inputs=inputs, outputs=output_layer)
  # Set compile parameters
  epochs = 2
  learn_rate_drop_period = 1000
  initial_learn_rate = 0.01
  learn_rate_drop_factor = 0.1
  validation_frequency = 1

  # Compile the model with mean squared error loss and additional parameters
  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
      initial_learn_rate, decay_steps=learn_rate_drop_period, decay_rate=learn_rate_drop_factor
    )
  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
                loss='mean_squared_error')

 # Train the model on the training data
  history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))

  # Evaluate the model on the test data
  test_loss= model.evaluate(x_test, y_test, verbose=0)

  # Evaluate the model on the test data
  train_loss= model.evaluate(x_train, y_train, verbose=0)

  # Make predictions on the test data
  y_pred = model.predict(x_test)
  # Calculate the root mean squared error percentage (RMSE%)
  rmse_percentage = np.sqrt(mean_squared_error(y_test, y_pred)) * 400

  # Calculate the mean absolute error percentage (MAE%)
  mae_percentage = mean_absolute_error(y_test, y_pred) * 500

  # Calculate the maximum absolute error percentage (max error%)
  max_abs_error_percentage = max_error(y_test, y_pred)* 100

  wdnn_rmse_values.append(rmse_percentage)
  wdnn_mae_values.append(mae_percentage)
  wdnn_max_abs_error_values.append(max_abs_error_percentage)

    # Print the accuracy metrics
  print("Test Loss:", test_loss)
  print("Train Loss:", train_loss)
  print("RMSE:", rmse_percentage)
  print("MAE:", mae_percentage)
  print("Max Absolute Error:", max_abs_error_percentage)

import matplotlib.pyplot as plt
plt.figure(figsize=(14, 8))
# Plot the loss values for training and validation sets
plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'])
plt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])

# Set the title, x-axis and y-axis labels, and legend
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')

# Set the x-axis ticks to integer values
plt.xticks(range(1, len(history.history['loss']) + 1))

# Display the plot
plt.show()

test_labels_vertical = pd.Series(np.ravel(y_test))
test_labels_vertical = test_labels_vertical.values.reshape(-1, 1)
test_labels_vertical = np.around(test_labels_vertical, decimals=2)
print(test_labels_vertical)
print(test_labels_vertical)
len(test_labels_vertical)

test_predictions_vertical = y_pred.reshape(len(y_pred),1)
test_predictions_vertical  = np.around(test_predictions_vertical , decimals=2)
print(test_predictions_vertical)
len(test_predictions_vertical)

true_pred = np.concatenate((test_labels_vertical,test_predictions_vertical),axis=1)
true_pred = np.around(true_pred, decimals=2)
print(true_pred)

import matplotlib.pyplot as plt
plt.scatter(test_labels_vertical, test_predictions_vertical, c='red', label='Predicted SOC')
plt.scatter(test_labels_vertical, test_labels_vertical, c='blue', label='Ideal SOC')
plt.xlabel('Actual SOC from dataset')
plt.xlim(left=0.1, right=1.1)
plt.ylabel('Predicted SOC by model')
plt.ylim(bottom=0.1, top=1.1)
plt.title('Scatter Plot of test and predicted soc')
plt.legend(loc='upper left')
plt.show()

import matplotlib.pyplot as plt
# Plot the Root mean square error (RMSE)
plt.bar(range(1,4), wdnn_rmse_values, label='RMSE', color='#c7b8e2',width=0.3)
plt.legend()
# Set the x-axis ticks to integer values
plt.xticks(range(1, 4))
plt.xlabel('Iterations')
plt.ylabel('Error %')
plt.title('Root mean square error')
plt.show()

# Plot the Mean Absolute error (MAE)
plt.bar(range(1,4), wdnn_mae_values, label='MAE', color='#F0E68C',width=0.3)
plt.legend()
# Set the x-axis ticks to integer values
plt.xticks(range(1, 4))
plt.xlabel('Iterations')
plt.ylabel('Error %')
plt.title('Mean Absolute Error')
plt.show()

# Plot the Maximum Absolute Error (MAX)
plt.bar(range(1,4), wdnn_max_abs_error_values, label='Max Abs Error', color='pink',width=0.3)
plt.legend()
# Set the x-axis ticks to integer values
plt.xticks(range(1, 4))
plt.xlabel('Iterations')
plt.ylabel('Error %')
plt.title('Maximum Absolute Error')
plt.show()

model.summary()